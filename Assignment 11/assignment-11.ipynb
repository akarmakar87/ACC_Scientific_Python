{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Assignment 11 - Asha Karmakar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In your own words, describe the commonalities and differences between NumPy arrays and Pandas series.\n",
    "\n",
    "Similarities:\n",
    "- A specific index can be accessed from both a Panda series and a NumPy array using square bracket [] notation\n",
    "- Both have array capabilities such as slicing\n",
    "\n",
    "Differences:\n",
    "- A Panda series is more flexible than a 1D NumPy array\n",
    "- A Panda series allows you to add your own set of indices instead of just 0,1,2,3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      Washington\n",
       "2       Jefferson\n",
       "5         Lincoln\n",
       "10       Hamilton\n",
       "20        Jackson\n",
       "50          Grant\n",
       "100      Franklin\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas series named bill_names with American currency bill denominations as indices and President last names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "bill_names = {1: 'Washington',\n",
    "              2: 'Jefferson',\n",
    "              5: 'Lincoln',\n",
    "             10: 'Hamilton',\n",
    "             20: 'Jackson',\n",
    "             50: 'Grant',\n",
    "            100: 'Franklin'}\n",
    "\n",
    "pd.Series(bill_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Pepper: Dark soft drinks scare me\n",
      "Lemonade           Very refreshing\n",
      "Sprite      My favorite soft drink\n",
      "Water            Necessary to live\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas series-as-dictionary beverages_dict. \n",
    "    \n",
    "beverages_dict = {'Dr. Pepper': 'Dark soft drinks scare me',\n",
    "                   'Lemonade': 'Very refreshing',\n",
    "                   'Sprite': 'My favorite soft drink',\n",
    "                   'Water': 'Necessary to live'}\n",
    "\n",
    "beverages = pd.Series(beverages_dict)\n",
    "\n",
    "# individual values via the keys\n",
    "print (\"Dr. Pepper:\",beverages['Dr. Pepper'])\n",
    "\n",
    "# multiple values via slicing\n",
    "print (beverages['Lemonade':'Water'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chongquing     15872000\n",
       "Shanghai       27058000\n",
       "Tokyo          37393000\n",
       "Moscow         12538000\n",
       "Mexico City    21782000\n",
       "London          9304000\n",
       "New York       18804000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a series-as-dictionary named population based on this information\n",
    "\n",
    "population_dict = {'Chongquing': 15872000,\n",
    "                   'Shanghai': 27058000,\n",
    "                   'Tokyo': 37393000,\n",
    "                   'Moscow': 12538000,\n",
    "                   'Mexico City': 21782000,\n",
    "                   'London': 9304000,\n",
    "                   'New York': 18804000}\n",
    "\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chongquing      China\n",
       "Shanghai        China\n",
       "Tokyo           Japan\n",
       "Moscow         Russia\n",
       "Mexico City    Mexico\n",
       "London             UK\n",
       "New York          USA\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas series-as-dictionary named city_country with the cities in population and the countries for each city.\n",
    "\n",
    "city_country_dict = {'Chongquing':'China',\n",
    "                'Shanghai':'China',\n",
    "                'Tokyo':'Japan',\n",
    "                'Moscow':'Russia',\n",
    "                'Mexico City': 'Mexico',\n",
    "                'London': 'UK',\n",
    "                'New York': 'USA'}\n",
    "\n",
    "city_country = pd.Series(city_country_dict)\n",
    "city_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: Index(['Chongquing', 'Shanghai', 'Tokyo', 'Moscow', 'Mexico City', 'London',\n",
      "       'New York'],\n",
      "      dtype='object')\n",
      "Columns: Index(['population', 'country'], dtype='object')\n",
      "Keys: Index(['population', 'country'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe object named city_dataframe from a dictionary of series objects\n",
    "\n",
    "city_dataframe = pd.DataFrame({'population': population,'country': city_country})\n",
    "\n",
    "# the .index property\n",
    "print (\"Index:\", city_dataframe.index)\n",
    "\n",
    "# the .columns property\n",
    "print (\"Columns:\", city_dataframe.columns)\n",
    "\n",
    "# the .keys() method\n",
    "print (\"Keys:\", city_dataframe.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slicing by explicit index:\n",
      " a    13\n",
      "b    24\n",
      "c    35\n",
      "dtype: int64\n",
      "\n",
      "slicing by implicit index:\n",
      " a    13\n",
      "b    24\n",
      "dtype: int64\n",
      "\n",
      "masking:\n",
      " b    24\n",
      "d    46\n",
      "dtype: int64\n",
      "\n",
      "fancy indexing:\n",
      " a    13\n",
      "c    35\n",
      "dtype: int64\n",
      "\n",
      "loc[]:\n",
      " b    24\n",
      "c    35\n",
      "d    46\n",
      "dtype: int64\n",
      "\n",
      "iloc[]:\n",
      " c    35\n",
      "d    46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a Pandas series object named my_pd_series from a collection of string keys and collection of numeric values \n",
    "\n",
    "my_pd_series = data = pd.Series([13, 24, 35, 46],index=['a', 'b', 'c', 'd'])\n",
    "\n",
    "# modifying a value based on key\n",
    "my_pd_series['a']\n",
    "\n",
    "# slicing by explicit index\n",
    "print (\"slicing by explicit index:\\n\", my_pd_series['a':'c'])\n",
    "\n",
    "# slicing by implicit integer index\n",
    "print (\"\\nslicing by implicit index:\\n\", my_pd_series[0:2])\n",
    "\n",
    "# masking\n",
    "print (\"\\nmasking:\\n\", my_pd_series[my_pd_series % 2 == 0])\n",
    "\n",
    "# fancy indexing\n",
    "print (\"\\nfancy indexing:\\n\", my_pd_series[['a','c']])\n",
    "\n",
    "# loc[]\n",
    "print (\"\\nloc[]:\\n\", my_pd_series.loc['b':'d'])\n",
    "\n",
    "# iloc[]\n",
    "print (\"\\niloc[]:\\n\", my_pd_series.iloc[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access column via dictionary-style indexing of the column name:\n",
      " Chongquing      China\n",
      "Shanghai        China\n",
      "Tokyo           Japan\n",
      "Moscow         Russia\n",
      "Mexico City    Mexico\n",
      "London             UK\n",
      "New York          USA\n",
      "Name: country, dtype: object\n",
      "\n",
      "access column via column names that are strings:\n",
      " Chongquing      China\n",
      "Shanghai        China\n",
      "Tokyo           Japan\n",
      "Moscow         Russia\n",
      "Mexico City    Mexico\n",
      "London             UK\n",
      "New York          USA\n",
      "Name: country, dtype: object\n",
      "\n",
      "add a new column to the city_dataframe named altitude:\n",
      "              population country  altitude\n",
      "Chongquing     15872000   China    801.00\n",
      "Shanghai       27058000   China     13.12\n",
      "Tokyo          37393000   Japan    131.00\n",
      "Moscow         12538000  Russia    512.00\n",
      "Mexico City    21782000  Mexico   7382.00\n",
      "London          9304000      UK     36.00\n",
      "New York       18804000     USA     33.00\n"
     ]
    }
   ],
   "source": [
    "# Using city_dataframe, demonstrate:\n",
    "\n",
    "# access column via dictionary-style indexing of the column name\n",
    "print (\"access column via dictionary-style indexing of the column name:\\n\", city_dataframe['country'])\n",
    "\n",
    "# access column via column names that are strings\n",
    "print (\"\\naccess column via column names that are strings:\\n\", city_dataframe.country)\n",
    "\n",
    "# add a new column to the city_dataframe named altitude.\n",
    "altitude = pd.Series({'Chongquing': 801,\n",
    "                      'Shanghai': 13.12,\n",
    "                      'Tokyo': 131,\n",
    "                      'Moscow': 512,\n",
    "                      'Mexico City': 7382,\n",
    "                      'London': 36,\n",
    "                      'New York': 33})\n",
    "city_dataframe['altitude'] = altitude\n",
    "print (\"\\nadd a new column to the city_dataframe named altitude:\\n\", city_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when added using ‘+’ produces some NaN entries:\n",
      " a     NaN\n",
      "b     NaN\n",
      "c     8.0\n",
      "d    10.0\n",
      "e     NaN\n",
      "f     NaN\n",
      "dtype: float64\n",
      "\n",
      "use the .add() method and a fill_value to replace the NaN entries:\n",
      " a     1.0\n",
      "b     2.0\n",
      "c     8.0\n",
      "d    10.0\n",
      "e     7.0\n",
      "f     8.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create two Pandas series that when added using ‘+’ produce some NaN entries. \n",
    "\n",
    "a_series = pd.Series([1,2,3,4],index=['a','b','c','d'])\n",
    "b_series = pd.Series([5,6,7,8],index=['c','d','e','f'])\n",
    "\n",
    "print (\"when added using ‘+’ produces some NaN entries:\\n\", a_series + b_series)\n",
    "\n",
    "# Use the .add() method and a fill_value to replace the NaN entries\n",
    "print (\"\\nuse the .add() method and a fill_value to replace the NaN entries:\\n\", a_series.add(b_series, fill_value = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first array:\n",
      "     A   B\n",
      "0  38  18\n",
      "1   1   1\n",
      "\n",
      "second array:\n",
      "     B   C\n",
      "0  40  27\n",
      "1  18  19\n",
      "\n",
      "added using '+':\n",
      "     A   B   C\n",
      "0 NaN  58 NaN\n",
      "1 NaN  19 NaN\n",
      "\n",
      "added using .add:\n",
      "       A   B     C\n",
      "0  52.5  58  41.5\n",
      "1  15.5  19  33.5\n"
     ]
    }
   ],
   "source": [
    "# Create two Pandas dataframes  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a_df = pd.DataFrame(np.random.randint(0, 50, (2, 2)),columns=['A','B'])\n",
    "b_df = pd.DataFrame(np.random.randint(0, 50, (2, 2)),columns=['B','C'])\n",
    "\n",
    "print (\"first array:\\n\",a_df)\n",
    "print (\"\\nsecond array:\\n\",b_df)\n",
    "\n",
    "# when added using ‘+’ produce some NaN entries. \n",
    "print (\"\\nadded using '+':\\n\", a_df + b_df)\n",
    "\n",
    "# Use the .add() method and a fill_value of the mean of one of the dataframes to replace the NaN entries.\n",
    "print (\"\\nadded using .add:\\n\", a_df.add(b_df, fill_value = a_df.stack().mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[8 9 7 9]\n",
      " [9 6 7 7]\n",
      " [7 9 8 7]\n",
      " [9 6 8 6]]\n",
      "\n",
      "subtract row 0 of A from A:\n",
      "\n",
      "[[ 0  0  0  0]\n",
      " [ 1 -3  0 -2]\n",
      " [-1  0  1 -2]\n",
      " [ 1 -3  1 -3]]\n"
     ]
    }
   ],
   "source": [
    "# Create a two-dimensional NumPy array using:\n",
    "\n",
    "import numpy as np\n",
    "# ** What exactly does RandomState do? Does it store a set of random numbers? **\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "A = rng.randint(5, 10, size=(4, 4))\n",
    "\n",
    "print (\"A:\")\n",
    "print (A)\n",
    "\n",
    "# Demonstrate: subtracting row 0 of A from A\n",
    "\n",
    "print (\"\\nsubtract row 0 of A from A:\\n\")\n",
    "print (A-A[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q  R  S  T\n",
      "0  8  9  7  9\n",
      "1  9  6  7  7\n",
      "2  7  9  8  7\n",
      "3  9  6  8  6\n",
      "\n",
      "subtract row 1 of df from df using df.iloc[1]:\n",
      "\n",
      "   Q  R  S  T\n",
      "0 -1  3  0  2\n",
      "1  0  0  0  0\n",
      "2 -2  3  1  0\n",
      "3  0  0  1 -1\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe using: \n",
    "\n",
    "df = pd.DataFrame(A, columns=list('QRST'))\n",
    "print (df)\n",
    "\n",
    "# Demonstrate: subtracting row 1 of df from df using df.iloc[1]\n",
    "\n",
    "print (\"\\nsubtract row 1 of df from df using df.iloc[1]:\\n\")\n",
    "print (df - df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare and contrast the two sentinel values Pandas uses to represent missing data.\n",
    "The two sentinel values that Pandas uses to represent missing data are <b>none</b> and <b>NaN</b>.\n",
    "\n",
    "<b>None</b> can only be used in arrays with object datatype (not just any NumPy/Pandas array).\n",
    "<b>NaN</b>, which is an acronym for \"not a number\" is specifically used to represent missing <i>numerical</i> data.\n",
    "\n",
    "If you added np.nan to an array, it will automatically be upcasted to the 'float64' datatype. In the process, any None in the array is also upcasted to a NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype = object\n",
      "96.7 ms ± 2.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "dtype = int\n",
      "4.82 ms ± 679 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the %timeit difference between operations using Python objects and Python integers.\n",
    "\n",
    "for t in ['object', 'int']:\n",
    "    print(\"dtype =\", t)\n",
    "    %timeit np.arange(1E6, dtype=t).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2     NaN\n",
       "6    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas series containing null data. Use .isnull() to identify the entries that are null.\n",
    "\n",
    "test = pd.Series(['string', False, np.nan, 4.8, 15, 'hello', None])\n",
    "print (test.isnull())\n",
    "test[test.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1   2\n",
      "0   1.0   2.0   3\n",
      "1   4.0   NaN   6\n",
      "2   NaN   8.0   9\n",
      "3  10.0  11.0  12\n",
      "\n",
      "drop all rows containing a null value:\n",
      "\n",
      "      0     1   2\n",
      "0   1.0   2.0   3\n",
      "3  10.0  11.0  12\n",
      "\n",
      "drop all columns containing a null value:\n",
      "\n",
      "    2\n",
      "0   3\n",
      "1   6\n",
      "2   9\n",
      "3  12\n",
      "\n",
      "drop only columns that contain all null values:\n",
      "\n",
      "      1   2\n",
      "0   2.0   3\n",
      "1   NaN   6\n",
      "2   8.0   9\n",
      "3  11.0  12\n",
      "\n",
      "drop only rows that contain all null values:\n",
      "\n",
      "      0     1     2\n",
      "0   1.0   2.0   3.0\n",
      "2   NaN   8.0   9.0\n",
      "3  10.0  11.0  12.0\n",
      "\n",
      "replacing null with 0:\n",
      "\n",
      "      0     1     2\n",
      "0   1.0   2.0   3.0\n",
      "1   0.0   0.0   0.0\n",
      "2   0.0   8.0   9.0\n",
      "3  10.0  11.0  12.0\n",
      "\n",
      "forward fill:\n",
      "\n",
      "      0     1     2\n",
      "0   1.0   2.0   3.0\n",
      "1   1.0   2.0   3.0\n",
      "2   1.0   8.0   9.0\n",
      "3  10.0  11.0  12.0\n",
      "\n",
      "backward fill:\n",
      "\n",
      "      0     1     2\n",
      "0   1.0   2.0   3.0\n",
      "1  10.0   8.0   9.0\n",
      "2  10.0   8.0   9.0\n",
      "3  10.0  11.0  12.0\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas dataframe containing null values. Demonstrate:\n",
    "\n",
    "test_df = pd.DataFrame([[1, 2, 3],\n",
    "                        [4, np.nan, 6],\n",
    "                        [np.nan, 8, 9],\n",
    "                        [10, 11, 12]])\n",
    "print (test_df)\n",
    "\n",
    "# drop all rows containing a null value\n",
    "print (\"\\ndrop all rows containing a null value:\\n\")\n",
    "print (test_df.dropna())\n",
    "\n",
    "# drop all columns containing a null value\n",
    "print (\"\\ndrop all columns containing a null value:\\n\")\n",
    "print (test_df.dropna(axis=1))\n",
    "\n",
    "# drop only rows that contain all null values\n",
    "test_df[0] = np.nan\n",
    "print (\"\\ndrop only columns that contain all null values:\\n\")\n",
    "print (test_df.dropna(axis=1 , how='all'))\n",
    "\n",
    "# drop only columns that contain all null values\n",
    "test_df[0] = [1,4,np.nan,10]\n",
    "test_df.iloc[1] = np.nan\n",
    "print (\"\\ndrop only rows that contain all null values:\\n\")\n",
    "print (test_df.dropna(axis=0 , how='all'))\n",
    "\n",
    "# replacing null with 0\n",
    "print (\"\\nreplacing null with 0:\\n\")\n",
    "print (test_df.fillna(0))\n",
    "\n",
    "# forward fill\n",
    "print (\"\\nforward fill:\\n\")\n",
    "print (test_df.fillna(method='ffill'))\n",
    "\n",
    "# backward fill \n",
    "print (\"\\nbackward fill:\\n\")\n",
    "print (test_df.fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".from_tuples():\n",
      "\n",
      "MultiIndex([('California', 2000),\n",
      "            ('California', 2010),\n",
      "            (  'New York', 2000),\n",
      "            (  'New York', 2010),\n",
      "            (     'Texas', 2000),\n",
      "            (     'Texas', 2010)],\n",
      "           )\n",
      "\n",
      ".reindex():\n",
      "\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "\n",
      ".unstack():\n",
      "\n",
      "                2000      2010\n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n",
      "\n",
      ".stack():\n",
      "\n",
      "2000  California    33871648\n",
      "      New York      18976457\n",
      "      Texas         20851820\n",
      "2010  California    37253956\n",
      "      New York      19378102\n",
      "      Texas         25145561\n",
      "dtype: int64\n",
      "\n",
      "indexing and slicing:\n",
      "\n",
      "33871648\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate Pandas MultiIndex techniques:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "\n",
    "pop = pd.Series(populations, index=index)\n",
    "\n",
    "# .from_tuples()\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "print (\"\\n.from_tuples():\\n\")\n",
    "print (index)\n",
    "\n",
    "# .reindex()\n",
    "pop = pop.reindex(index)\n",
    "print (\"\\n.reindex():\\n\")\n",
    "print (pop)\n",
    "\n",
    "# .unstack()\n",
    "pop_df = pop.unstack()\n",
    "print (\"\\n.unstack():\\n\")\n",
    "print (pop_df)\n",
    "\n",
    "# .stack()\n",
    "print (\"\\n.stack():\\n\")\n",
    "print (pop_df.unstack())\n",
    "\n",
    "# indexing and slicing\n",
    "print (\"\\nindexing and slicing:\\n\")\n",
    "print (pop['California',2000])\n",
    "print (pop.loc['California':'New York'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RZA 372             Toyota\n",
       "WFZ 884            Porsche\n",
       "WCK 898             Subaru\n",
       "UCL 870             Yamaha\n",
       "ELD 657              Honda\n",
       "XXT 682    Harley-Davidson\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate concatenating two Pandas series. \n",
    "\n",
    "# One series contains automobile data. The other series contains motorcycle data.\n",
    "autos = pd.Series(['Toyota','Porsche','Subaru'], index = ['RZA 372','WFZ 884','WCK 898'])\n",
    "motorcycles = pd.Series(['Yamaha','Honda','Harley-Davidson'], index = ['UCL 870', 'ELD 657','XXT 682'])\n",
    "pd.concat([autos, motorcycles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RZA 372</th>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WFZ 884</th>\n",
       "      <td>Porsche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WCK 898</th>\n",
       "      <td>Subaru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UCL 870</th>\n",
       "      <td>Yamaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELD 657</th>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XXT 682</th>\n",
       "      <td>Harley-Davidson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Manufacturer\n",
       "RZA 372           Toyota\n",
       "WFZ 884          Porsche\n",
       "WCK 898           Subaru\n",
       "UCL 870           Yamaha\n",
       "ELD 657            Honda\n",
       "XXT 682  Harley-Davidson"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate concatenating two Pandas dataframe using the .append() method.\n",
    "\n",
    "autos_df = pd.DataFrame(autos,columns=['Manufacturer'])\n",
    "motorcycles_df = pd.DataFrame(motorcycles,columns=['Manufacturer'])\n",
    "\n",
    "autos_df.append(motorcycles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-to-one:\n",
      "\n",
      "  team_member    subteam  years\n",
      "0        Asha   Software      3\n",
      "1       Mindy   Software      2\n",
      "2     Garrett   Software      2\n",
      "3       Jerry   Software      1\n",
      "4        Tobi   Hardware      2\n",
      "5        Neha   Hardware      2\n",
      "6        Luke   Hardware      3\n",
      "7      Pranav   Hardware      2\n",
      "8       Kenna        CAD      1\n",
      "9       Riley  Marketing      4\n",
      "\n",
      "many-to-one:\n",
      "\n",
      "  team_member    subteam  years subteam_lead\n",
      "0        Asha   Software      3         Asha\n",
      "1       Mindy   Software      2         Asha\n",
      "2     Garrett   Software      2         Asha\n",
      "3       Jerry   Software      1         Asha\n",
      "4        Tobi   Hardware      2       Pranav\n",
      "5        Neha   Hardware      2       Pranav\n",
      "6        Luke   Hardware      3       Pranav\n",
      "7      Pranav   Hardware      2       Pranav\n",
      "8       Kenna        CAD      1        Kenna\n",
      "9       Riley  Marketing      4        Riley\n",
      "\n",
      "many-to-many:\n",
      "\n",
      "  team_member    subteam    weekday\n",
      "0        Asha   Software   Thursday\n",
      "1       Mindy   Software   Thursday\n",
      "2     Garrett   Software   Thursday\n",
      "3       Jerry   Software   Thursday\n",
      "4        Tobi   Hardware     Monday\n",
      "5        Neha   Hardware     Monday\n",
      "6        Luke   Hardware     Monday\n",
      "7      Pranav   Hardware     Monday\n",
      "8       Kenna        CAD  Wednesday\n",
      "9       Riley  Marketing    Tuesday\n"
     ]
    }
   ],
   "source": [
    "# Using Pandas dataframes, demonstrate the following joins:\n",
    "\n",
    "df1 = pd.DataFrame({'team_member': ['Asha','Mindy','Garrett','Jerry','Tobi','Neha','Luke','Pranav','Kenna','Riley'],\n",
    "                    'subteam': ['Software','Software','Software','Software','Hardware','Hardware',\n",
    "                                'Hardware','Hardware', 'CAD', 'Marketing']})\n",
    "\n",
    "df2 = pd.DataFrame({'team_member': ['Asha','Mindy','Garrett','Jerry','Tobi','Neha','Luke','Riley','Kenna','Pranav'],\n",
    "                    'years': [3,2,2,1,2,2,3,4,1,2]})\n",
    "\n",
    "df3 = pd.merge(df1, df2)\n",
    "\n",
    "df4 = pd.DataFrame({'subteam': ['Software', 'Marketing', 'CAD', 'Hardware'],\n",
    "                    'subteam_lead': ['Asha', 'Riley', 'Kenna', 'Pranav']})\n",
    "\n",
    "df5 = pd.DataFrame({'subteam': ['Software', 'Marketing', 'CAD', 'Hardware'],\n",
    "                    'weekday': ['Thursday', 'Tuesday', 'Wednesday', 'Monday']})\n",
    "\n",
    "# one-to-one\n",
    "print (\"one-to-one:\\n\")\n",
    "print (pd.merge(df1, df2))\n",
    "\n",
    "# many-to-one: one of the two key columns contains duplicate entries\n",
    "print (\"\\nmany-to-one:\\n\")\n",
    "print (pd.merge(df3, df4))\n",
    "\n",
    "# many-to-many: one of the two key columns contains duplicate entries\n",
    "print (\"\\nmany-to-many:\\n\")\n",
    "print (pd.merge(df1, df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on:\n",
      "\n",
      "  team_member    subteam  years\n",
      "0        Asha   Software      3\n",
      "1       Mindy   Software      2\n",
      "2     Garrett   Software      2\n",
      "3       Jerry   Software      1\n",
      "4        Tobi   Hardware      2\n",
      "5        Neha   Hardware      2\n",
      "6        Luke   Hardware      3\n",
      "7      Pranav   Hardware      2\n",
      "8       Kenna        CAD      1\n",
      "9       Riley  Marketing      4\n",
      "\n",
      "left_on and right_on:\n",
      "\n",
      "  team_member    subteam viperbot  grade\n",
      "0        Asha   Software     Asha     11\n",
      "1       Mindy   Software    Mindy     12\n",
      "2     Garrett   Software  Garrett     11\n",
      "3       Jerry   Software    Jerry     10\n",
      "4        Tobi   Hardware     Tobi     12\n",
      "5        Neha   Hardware     Neha      9\n",
      "6        Luke   Hardware     Luke     10\n",
      "7      Pranav   Hardware   Pranav     11\n",
      "8       Kenna        CAD    Kenna     11\n",
      "9       Riley  Marketing    Riley     11\n",
      "\n",
      "left_index and right_index:\n",
      "\n",
      "               subteam  years\n",
      "team_member                  \n",
      "Asha          Software      3\n",
      "Mindy         Software      2\n",
      "Garrett       Software      2\n",
      "Jerry         Software      1\n",
      "Tobi          Hardware      2\n",
      "Neha          Hardware      2\n",
      "Luke          Hardware      3\n",
      "Pranav        Hardware      2\n",
      "Kenna              CAD      1\n",
      "Riley        Marketing      4\n"
     ]
    }
   ],
   "source": [
    "# Using Pandas dataframes, demonstrate merge with the following keywords:\n",
    "\n",
    "df6 = pd.DataFrame({'viperbot': ['Asha','Mindy','Garrett','Jerry','Tobi','Neha','Luke','Pranav','Kenna','Riley'],\n",
    "                    'grade': [11,12,11,10,12,9,10,11,11,11]})\n",
    "\n",
    "# on\n",
    "print (\"on:\\n\")\n",
    "print (pd.merge(df1, df2, on='team_member'))\n",
    "\n",
    "# left_on and right_on\n",
    "print (\"\\nleft_on and right_on:\\n\")\n",
    "print (pd.merge(df1, df6, left_on=\"team_member\", right_on=\"viperbot\"))\n",
    "\n",
    "# left_index and right_index\n",
    "df1a = df1.set_index('team_member')\n",
    "df2a = df2.set_index('team_member')\n",
    "print (\"\\nleft_index and right_index:\\n\")\n",
    "print (pd.merge(df1a, df2a, left_index=True, right_index=True)) # what exactly does True mean here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through completing Assignment 11 I learned how to create and manipulate pandas series and dataframes. I think the DataFrame is a really neat data structure and I like how it organizes the data so nicely. Overall, I was surprised by the large variety of built-in methods the pandas data structures offer; I think that's what makes it such a powerful and flexible tool for data manipulation. Earlier, when I was learning about PostgreSQL commands, I learned about the different types of table joins, which were kind of similar with the types of pandas DataFrame joins. There were a few things I was confused on: is a printed MultiIndex object supposed to be formatted like \"MultiIndex(levels= --,labels= --)\" ? Because when I printed the same MultiIndex object as the one in the book, it gave a differently formatted output. Another thing is, in the command \"pd.merge(df1a, df2a, left_index=True, right_index=True)\" what exactly does True mean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
