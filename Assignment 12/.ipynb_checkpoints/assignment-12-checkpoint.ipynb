{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Assignment 12 - Asha Karmakar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1035\n",
      "columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Using the Planets dataset from Seaborn, determine the number of rows and columns in the dataset\n",
    "\n",
    "import seaborn as sns\n",
    "planets = sns.load_dataset('planets')\n",
    "print (\"rows:\",planets.shape[0])\n",
    "print (\"columns:\",planets.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState(42): 0    0.374540\n",
      "1    0.950714\n",
      "2    0.731994\n",
      "3    0.598658\n",
      "4    0.156019\n",
      "dtype: float64\n",
      "\n",
      "RandomState(99): 0    0.672279\n",
      "1    0.488078\n",
      "2    0.825495\n",
      "3    0.031446\n",
      "4    0.808050\n",
      "dtype: float64\n",
      "\n",
      "RandomState(42): 0    0.374540\n",
      "1    0.950714\n",
      "2    0.731994\n",
      "3    0.598658\n",
      "4    0.156019\n",
      "5    0.155995\n",
      "6    0.058084\n",
      "7    0.866176\n",
      "8    0.601115\n",
      "9    0.708073\n",
      "dtype: float64\n",
      "\n",
      "RandomState(99): 0    0.672279\n",
      "1    0.488078\n",
      "2    0.825495\n",
      "3    0.031446\n",
      "4    0.808050\n",
      "5    0.565617\n",
      "6    0.297622\n",
      "7    0.046696\n",
      "8    0.990627\n",
      "9    0.006826\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use following seeds for RandomState()to demonstrate that the function returns the same random numbers for constant seeds:\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# RandomState(42)\n",
    "rng = np.random.RandomState(42)\n",
    "nums = pd.Series(rng.rand(5))\n",
    "print (\"RandomState(42):\", nums)\n",
    "\n",
    "# RandomState(99)\n",
    "rng = np.random.RandomState(99)\n",
    "nums = pd.Series(rng.rand(5))\n",
    "print (\"\\nRandomState(99):\", nums)\n",
    "\n",
    "# RandomState(42)\n",
    "rng = np.random.RandomState(42)\n",
    "nums = pd.Series(rng.rand(10))\n",
    "print (\"\\nRandomState(42):\", nums)\n",
    "\n",
    "# RandomState(99)\n",
    "rng = np.random.RandomState(99)\n",
    "nums = pd.Series(rng.rand(10))\n",
    "print (\"\\nRandomState(99):\", nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texas</th>\n",
       "      <th>Georgia</th>\n",
       "      <th>Main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769793</td>\n",
       "      <td>0.395454</td>\n",
       "      <td>0.211687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.746767</td>\n",
       "      <td>0.973956</td>\n",
       "      <td>0.554346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.377439</td>\n",
       "      <td>0.524415</td>\n",
       "      <td>0.292269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.494147</td>\n",
       "      <td>0.093613</td>\n",
       "      <td>0.816142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928948</td>\n",
       "      <td>0.813308</td>\n",
       "      <td>0.828043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Texas   Georgia      Main\n",
       "0  0.769793  0.395454  0.211687\n",
       "1  0.746767  0.973956  0.554346\n",
       "2  0.377439  0.524415  0.292269\n",
       "3  0.494147  0.093613  0.816142\n",
       "4  0.928948  0.813308  0.828043"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use rand(5) to produce the following dataframe. Naturally, values will vary.\n",
    "\n",
    "rand_df = pd.DataFrame({'Texas': rng.rand(5),'Georgia': rng.rand(5),'Main': rng.rand(5)})\n",
    "rand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498.00000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.73494</td>\n",
       "      <td>835.778671</td>\n",
       "      <td>2.509320</td>\n",
       "      <td>52.068213</td>\n",
       "      <td>2007.377510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.17572</td>\n",
       "      <td>1469.128259</td>\n",
       "      <td>3.636274</td>\n",
       "      <td>46.596041</td>\n",
       "      <td>4.167284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.328300</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>1989.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>38.272250</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>24.497500</td>\n",
       "      <td>2005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>1.245000</td>\n",
       "      <td>39.940000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>999.600000</td>\n",
       "      <td>2.867500</td>\n",
       "      <td>59.332500</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>17337.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          number  orbital_period        mass    distance         year\n",
       "count  498.00000      498.000000  498.000000  498.000000   498.000000\n",
       "mean     1.73494      835.778671    2.509320   52.068213  2007.377510\n",
       "std      1.17572     1469.128259    3.636274   46.596041     4.167284\n",
       "min      1.00000        1.328300    0.003600    1.350000  1989.000000\n",
       "25%      1.00000       38.272250    0.212500   24.497500  2005.000000\n",
       "50%      1.00000      357.000000    1.245000   39.940000  2009.000000\n",
       "75%      2.00000      999.600000    2.867500   59.332500  2011.000000\n",
       "max      6.00000    17337.500000   25.000000  354.000000  2014.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the common aggregates for the Pandas dataset dropping rows with missing values.\n",
    "\n",
    "planets.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anscombe',\n",
       " 'attention',\n",
       " 'brain_networks',\n",
       " 'car_crashes',\n",
       " 'diamonds',\n",
       " 'dots',\n",
       " 'exercise',\n",
       " 'flights',\n",
       " 'fmri',\n",
       " 'gammas',\n",
       " 'geyser',\n",
       " 'iris',\n",
       " 'mpg',\n",
       " 'penguins',\n",
       " 'planets',\n",
       " 'tips',\n",
       " 'titanic']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output a list of the datasets that install with Seaborn.\n",
    "\n",
    "five = sns.get_dataset_names()\n",
    "five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATASET:attention\n",
      "   Unnamed: 0  subject attention  solutions  score\n",
      "0           0        1   divided          1    2.0\n",
      "1           1        2   divided          1    3.0\n",
      "2           2        3   divided          1    3.0\n",
      "3           3        4   divided          1    5.0\n",
      "4           4        5   divided          1    4.0\n",
      "\n",
      "DATASET:car_crashes\n",
      "   total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
      "0   18.8     7.332    5.640          18.048       15.040       784.55   \n",
      "1   18.1     7.421    4.525          16.290       17.014      1053.48   \n",
      "2   18.6     6.510    5.208          15.624       17.856       899.47   \n",
      "3   22.4     4.032    5.824          21.056       21.280       827.34   \n",
      "4   12.0     4.200    3.360          10.920       10.680       878.41   \n",
      "\n",
      "   ins_losses abbrev  \n",
      "0      145.08     AL  \n",
      "1      133.93     AK  \n",
      "2      110.35     AZ  \n",
      "3      142.39     AR  \n",
      "4      165.63     CA  \n",
      "\n",
      "DATASET:dots\n",
      "  align choice  time  coherence  firing_rate\n",
      "0  dots     T1   -80        0.0    33.189967\n",
      "1  dots     T1   -80        3.2    31.691726\n",
      "2  dots     T1   -80        6.4    34.279840\n",
      "3  dots     T1   -80       12.8    32.631874\n",
      "4  dots     T1   -80       25.6    35.060487\n",
      "\n",
      "DATASET:flights\n",
      "   year     month  passengers\n",
      "0  1949   January         112\n",
      "1  1949  February         118\n",
      "2  1949     March         132\n",
      "3  1949     April         129\n",
      "4  1949       May         121\n",
      "\n",
      "DATASET:gammas\n",
      "   timepoint  ROI  subject  BOLD signal\n",
      "0        0.0  IPS        0     0.513433\n",
      "1        0.0  IPS        1    -0.414368\n",
      "2        0.0  IPS        2     0.214695\n",
      "3        0.0  IPS        3     0.814809\n",
      "4        0.0  IPS        4    -0.894992\n"
     ]
    }
   ],
   "source": [
    "# Output the top five rows of five Pandas datasets:\n",
    "\n",
    "for d in five[1:10:2]:\n",
    "    print (\"\\nDATASET:\"+d)\n",
    "    print (sns.load_dataset(d).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirement 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">number</th>\n",
       "      <th colspan=\"2\" halign=\"left\">orbital_period</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">mass</th>\n",
       "      <th colspan=\"8\" halign=\"left\">distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.888000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.6800</td>\n",
       "      <td>11.680</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.57</td>\n",
       "      <td>40.5700</td>\n",
       "      <td>40.570</td>\n",
       "      <td>40.5700</td>\n",
       "      <td>40.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.901950</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.211400</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.230785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.360000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.36</td>\n",
       "      <td>15.3600</td>\n",
       "      <td>15.360</td>\n",
       "      <td>15.3600</td>\n",
       "      <td>15.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.760682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>335.961656</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8725</td>\n",
       "      <td>3.900</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>3.343703</td>\n",
       "      <td>12.53</td>\n",
       "      <td>13.6225</td>\n",
       "      <td>14.840</td>\n",
       "      <td>17.4825</td>\n",
       "      <td>21.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.430000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.43</td>\n",
       "      <td>17.4300</td>\n",
       "      <td>17.430</td>\n",
       "      <td>17.4300</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>114.310661</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2756</td>\n",
       "      <td>8.020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.302000</td>\n",
       "      <td>16.855839</td>\n",
       "      <td>4.70</td>\n",
       "      <td>19.7200</td>\n",
       "      <td>21.290</td>\n",
       "      <td>37.8800</td>\n",
       "      <td>47.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.055597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>552.280919</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0765</td>\n",
       "      <td>8.440</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.947333</td>\n",
       "      <td>14.447872</td>\n",
       "      <td>10.91</td>\n",
       "      <td>18.5650</td>\n",
       "      <td>29.760</td>\n",
       "      <td>40.4700</td>\n",
       "      <td>59.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.687500</td>\n",
       "      <td>1.014479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>540.945323</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2475</td>\n",
       "      <td>18.100</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.752500</td>\n",
       "      <td>18.042758</td>\n",
       "      <td>3.22</td>\n",
       "      <td>18.0850</td>\n",
       "      <td>32.865</td>\n",
       "      <td>37.3400</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>735.304392</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0450</td>\n",
       "      <td>10.350</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.531667</td>\n",
       "      <td>18.152531</td>\n",
       "      <td>14.08</td>\n",
       "      <td>24.3375</td>\n",
       "      <td>33.650</td>\n",
       "      <td>42.2450</td>\n",
       "      <td>77.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>0.877588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>971.834186</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9500</td>\n",
       "      <td>17.400</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.396129</td>\n",
       "      <td>23.294079</td>\n",
       "      <td>12.53</td>\n",
       "      <td>32.2850</td>\n",
       "      <td>37.440</td>\n",
       "      <td>49.1450</td>\n",
       "      <td>121.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2182.036515</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9475</td>\n",
       "      <td>18.370</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.085417</td>\n",
       "      <td>29.760336</td>\n",
       "      <td>11.11</td>\n",
       "      <td>27.4600</td>\n",
       "      <td>35.955</td>\n",
       "      <td>46.2700</td>\n",
       "      <td>133.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1.576923</td>\n",
       "      <td>1.101747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>538.038556</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2700</td>\n",
       "      <td>3.690</td>\n",
       "      <td>23.0</td>\n",
       "      <td>184.777826</td>\n",
       "      <td>518.812277</td>\n",
       "      <td>10.23</td>\n",
       "      <td>35.5150</td>\n",
       "      <td>48.950</td>\n",
       "      <td>71.5000</td>\n",
       "      <td>2500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.641026</td>\n",
       "      <td>1.063440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>741.982000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5125</td>\n",
       "      <td>14.000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>46.484324</td>\n",
       "      <td>48.886078</td>\n",
       "      <td>4.70</td>\n",
       "      <td>20.9800</td>\n",
       "      <td>35.870</td>\n",
       "      <td>55.0400</td>\n",
       "      <td>300.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.387097</td>\n",
       "      <td>0.843699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26762.097097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9500</td>\n",
       "      <td>7.600</td>\n",
       "      <td>28.0</td>\n",
       "      <td>660.228929</td>\n",
       "      <td>2214.828664</td>\n",
       "      <td>8.77</td>\n",
       "      <td>17.8825</td>\n",
       "      <td>46.940</td>\n",
       "      <td>89.6375</td>\n",
       "      <td>8500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.226415</td>\n",
       "      <td>0.697289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>363.759133</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1775</td>\n",
       "      <td>19.800</td>\n",
       "      <td>45.0</td>\n",
       "      <td>162.656000</td>\n",
       "      <td>300.327248</td>\n",
       "      <td>4.54</td>\n",
       "      <td>52.8300</td>\n",
       "      <td>80.580</td>\n",
       "      <td>148.0000</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>74.0</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>1.178607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9394.701194</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9100</td>\n",
       "      <td>25.000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>98.680312</td>\n",
       "      <td>115.811291</td>\n",
       "      <td>4.94</td>\n",
       "      <td>33.6300</td>\n",
       "      <td>56.070</td>\n",
       "      <td>123.9550</td>\n",
       "      <td>680.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>98.0</td>\n",
       "      <td>1.336735</td>\n",
       "      <td>0.624976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1346.422722</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3125</td>\n",
       "      <td>21.420</td>\n",
       "      <td>83.0</td>\n",
       "      <td>82.056747</td>\n",
       "      <td>92.308976</td>\n",
       "      <td>8.52</td>\n",
       "      <td>35.9700</td>\n",
       "      <td>52.830</td>\n",
       "      <td>102.4450</td>\n",
       "      <td>550.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>102.0</td>\n",
       "      <td>1.892157</td>\n",
       "      <td>1.652522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>669.542656</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1600</td>\n",
       "      <td>13.000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>256.796344</td>\n",
       "      <td>388.725207</td>\n",
       "      <td>4.70</td>\n",
       "      <td>39.3900</td>\n",
       "      <td>90.000</td>\n",
       "      <td>343.0000</td>\n",
       "      <td>2700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>185.0</td>\n",
       "      <td>1.913514</td>\n",
       "      <td>1.199221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>706.967833</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5500</td>\n",
       "      <td>13.650</td>\n",
       "      <td>155.0</td>\n",
       "      <td>319.015032</td>\n",
       "      <td>510.919926</td>\n",
       "      <td>6.06</td>\n",
       "      <td>28.3200</td>\n",
       "      <td>87.870</td>\n",
       "      <td>312.3450</td>\n",
       "      <td>2250.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.842857</td>\n",
       "      <td>1.074702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>476.060685</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>11.100</td>\n",
       "      <td>91.0</td>\n",
       "      <td>563.286154</td>\n",
       "      <td>1114.804739</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54.0150</td>\n",
       "      <td>200.000</td>\n",
       "      <td>462.5000</td>\n",
       "      <td>7720.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>118.0</td>\n",
       "      <td>2.347458</td>\n",
       "      <td>1.716571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.241233</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>20.600</td>\n",
       "      <td>71.0</td>\n",
       "      <td>529.767746</td>\n",
       "      <td>1148.299048</td>\n",
       "      <td>6.80</td>\n",
       "      <td>52.5550</td>\n",
       "      <td>132.000</td>\n",
       "      <td>511.5000</td>\n",
       "      <td>7560.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.234710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>300.863421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5400</td>\n",
       "      <td>2.580</td>\n",
       "      <td>6.0</td>\n",
       "      <td>359.836667</td>\n",
       "      <td>378.741759</td>\n",
       "      <td>20.48</td>\n",
       "      <td>106.9050</td>\n",
       "      <td>272.000</td>\n",
       "      <td>433.0000</td>\n",
       "      <td>1056.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number                                               orbital_period  \\\n",
       "      count      mean       std  min  25%  50%   75%  max          count   \n",
       "year                                                                       \n",
       "1989    1.0  1.000000       NaN  1.0  1.0  1.0  1.00  1.0            1.0   \n",
       "1992    2.0  3.000000  0.000000  3.0  3.0  3.0  3.00  3.0            2.0   \n",
       "1994    1.0  3.000000       NaN  3.0  3.0  3.0  3.00  3.0            1.0   \n",
       "1995    1.0  1.000000       NaN  1.0  1.0  1.0  1.00  1.0            1.0   \n",
       "1996    6.0  2.500000  1.760682  1.0  1.0  2.0  3.75  5.0            6.0   \n",
       "1997    1.0  1.000000       NaN  1.0  1.0  1.0  1.00  1.0            1.0   \n",
       "1998    5.0  2.200000  1.095445  1.0  2.0  2.0  2.00  4.0            5.0   \n",
       "1999   15.0  1.600000  1.055597  1.0  1.0  1.0  2.00  4.0           15.0   \n",
       "2000   16.0  1.687500  1.014479  1.0  1.0  1.0  2.00  4.0           16.0   \n",
       "2001   12.0  1.250000  0.621582  1.0  1.0  1.0  1.00  3.0           12.0   \n",
       "2002   32.0  1.437500  0.877588  1.0  1.0  1.0  2.00  5.0           32.0   \n",
       "2003   25.0  1.400000  0.645497  1.0  1.0  1.0  2.00  3.0           25.0   \n",
       "2004   26.0  1.576923  1.101747  1.0  1.0  1.0  2.00  5.0           22.0   \n",
       "2005   39.0  1.641026  1.063440  1.0  1.0  1.0  2.00  4.0           38.0   \n",
       "2006   31.0  1.387097  0.843699  1.0  1.0  1.0  1.00  4.0           28.0   \n",
       "2007   53.0  1.226415  0.697289  1.0  1.0  1.0  1.00  5.0           52.0   \n",
       "2008   74.0  1.621622  1.178607  1.0  1.0  1.0  2.00  6.0           69.0   \n",
       "2009   98.0  1.336735  0.624976  1.0  1.0  1.0  1.75  3.0           96.0   \n",
       "2010  102.0  1.892157  1.652522  1.0  1.0  1.0  2.00  6.0           96.0   \n",
       "2011  185.0  1.913514  1.199221  1.0  1.0  2.0  2.00  6.0          184.0   \n",
       "2012  140.0  1.842857  1.074702  1.0  1.0  2.0  2.00  6.0          132.0   \n",
       "2013  118.0  2.347458  1.716571  1.0  1.0  2.0  2.00  7.0          107.0   \n",
       "2014   52.0  2.250000  1.234710  1.0  1.0  2.0  3.00  5.0           51.0   \n",
       "\n",
       "                    ...     mass         distance                           \\\n",
       "              mean  ...      75%     max    count        mean          std   \n",
       "year                ...                                                      \n",
       "1989     83.888000  ...  11.6800  11.680      1.0   40.570000          NaN   \n",
       "1992     45.901950  ...      NaN     NaN      0.0         NaN          NaN   \n",
       "1994     98.211400  ...      NaN     NaN      0.0         NaN          NaN   \n",
       "1995      4.230785  ...   0.4720   0.472      1.0   15.360000          NaN   \n",
       "1996    335.961656  ...   2.8725   3.900      6.0   15.866667     3.343703   \n",
       "1997     39.845000  ...   1.0400   1.040      1.0   17.430000          NaN   \n",
       "1998    114.310661  ...   2.2756   8.020      5.0   26.302000    16.855839   \n",
       "1999    552.280919  ...   4.0765   8.440     15.0   30.947333    14.447872   \n",
       "2000    540.945323  ...   3.2475  18.100     16.0   30.752500    18.042758   \n",
       "2001    735.304392  ...   5.0450  10.350     12.0   36.531667    18.152531   \n",
       "2002    971.834186  ...   4.9500  17.400     31.0   44.396129    23.294079   \n",
       "2003   2182.036515  ...   4.9475  18.370     24.0   43.085417    29.760336   \n",
       "2004    538.038556  ...   2.2700   3.690     23.0  184.777826   518.812277   \n",
       "2005    741.982000  ...   2.5125  14.000     37.0   46.484324    48.886078   \n",
       "2006  26762.097097  ...   1.9500   7.600     28.0  660.228929  2214.828664   \n",
       "2007    363.759133  ...   3.1775  19.800     45.0  162.656000   300.327248   \n",
       "2008   9394.701194  ...   4.9100  25.000     64.0   98.680312   115.811291   \n",
       "2009   1346.422722  ...   4.3125  21.420     83.0   82.056747    92.308976   \n",
       "2010    669.542656  ...   1.1600  13.000     93.0  256.796344   388.725207   \n",
       "2011    706.967833  ...   1.5500  13.650    155.0  319.015032   510.919926   \n",
       "2012    476.060685  ...   6.2000  11.100     91.0  563.286154  1114.804739   \n",
       "2013    133.241233  ...   2.2000  20.600     71.0  529.767746  1148.299048   \n",
       "2014    300.863421  ...   1.5400   2.580      6.0  359.836667   378.741759   \n",
       "\n",
       "                                                   \n",
       "        min       25%      50%       75%      max  \n",
       "year                                               \n",
       "1989  40.57   40.5700   40.570   40.5700    40.57  \n",
       "1992    NaN       NaN      NaN       NaN      NaN  \n",
       "1994    NaN       NaN      NaN       NaN      NaN  \n",
       "1995  15.36   15.3600   15.360   15.3600    15.36  \n",
       "1996  12.53   13.6225   14.840   17.4825    21.41  \n",
       "1997  17.43   17.4300   17.430   17.4300    17.43  \n",
       "1998   4.70   19.7200   21.290   37.8800    47.92  \n",
       "1999  10.91   18.5650   29.760   40.4700    59.03  \n",
       "2000   3.22   18.0850   32.865   37.3400    80.00  \n",
       "2001  14.08   24.3375   33.650   42.2450    77.82  \n",
       "2002  12.53   32.2850   37.440   49.1450   121.36  \n",
       "2003  11.11   27.4600   35.955   46.2700   133.16  \n",
       "2004  10.23   35.5150   48.950   71.5000  2500.00  \n",
       "2005   4.70   20.9800   35.870   55.0400   300.30  \n",
       "2006   8.77   17.8825   46.940   89.6375  8500.00  \n",
       "2007   4.54   52.8300   80.580  148.0000  2000.00  \n",
       "2008   4.94   33.6300   56.070  123.9550   680.00  \n",
       "2009   8.52   35.9700   52.830  102.4450   550.00  \n",
       "2010   4.70   39.3900   90.000  343.0000  2700.00  \n",
       "2011   6.06   28.3200   87.870  312.3450  2250.00  \n",
       "2012   1.35   54.0150  200.000  462.5000  7720.00  \n",
       "2013   6.80   52.5550  132.000  511.5000  7560.00  \n",
       "2014  20.48  106.9050  272.000  433.0000  1056.00  \n",
       "\n",
       "[23 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the describe() method to a planets.groupby() object.\n",
    "\n",
    "planets.groupby('year').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       method                       \n",
       "count  Astrometry                          2.0\n",
       "       Eclipse Timing Variations           9.0\n",
       "       Imaging                            38.0\n",
       "       Microlensing                       23.0\n",
       "       Orbital Brightness Modulation       3.0\n",
       "                                         ...  \n",
       "max    Pulsar Timing                    2011.0\n",
       "       Pulsation Timing Variations      2007.0\n",
       "       Radial Velocity                  2014.0\n",
       "       Transit                          2014.0\n",
       "       Transit Timing Variations        2014.0\n",
       "Length: 80, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the describe() and unstack() methods to a planets.groupby() object\n",
    "\n",
    "# Gives an idea of the time period that each method was used the most \n",
    "planets.groupby('method')['year'].describe().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>Second</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
       "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
       "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
       "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
       "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  \n",
       "5    man        True  NaN   Queenstown    no   True  \n",
       "6    man        True    E  Southampton    no   True  \n",
       "7  child       False  NaN  Southampton    no  False  \n",
       "8  woman       False  NaN  Southampton   yes  False  \n",
       "9  child       False  NaN    Cherbourg   yes  False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first ten rows from the Seaborn titanic dataset.\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.135447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class      First    Second     Third\n",
       "sex                                 \n",
       "female  0.968085  0.921053  0.500000\n",
       "male    0.368852  0.157407  0.135447"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the groupby() method with the titanic dataset to show mean survival rates by sex and class\n",
    "\n",
    "titanic.groupby(['sex','class'])['survived'].aggregate('mean').unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.368852</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.135447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class      First    Second     Third\n",
       "sex                                 \n",
       "female  0.968085  0.921053  0.500000\n",
       "male    0.368852  0.157407  0.135447"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pivot_table() method with the titanic dataset to show mean survival rates by sex and class\n",
    "\n",
    "titanic.pivot_table('survived', index='sex', columns='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">female</th>\n",
       "      <th>(0, 18]</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18, 80]</th>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.423729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">male</th>\n",
       "      <th>(0, 18]</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.215686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(18, 80]</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.133663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class               First    Second     Third\n",
       "sex    age                                   \n",
       "female (0, 18]   0.909091  1.000000  0.511628\n",
       "       (18, 80]  0.972973  0.900000  0.423729\n",
       "male   (0, 18]   0.800000  0.600000  0.215686\n",
       "       (18, 80]  0.375000  0.071429  0.133663"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a multi-level pivot table to include age with the previous requirement\n",
    "\n",
    "age = pd.cut(titanic['age'], [0, 18, 80])\n",
    "titanic.pivot_table('survived', ['sex', age], 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">fare</th>\n",
       "      <th colspan=\"3\" halign=\"left\">survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "      <th>First</th>\n",
       "      <th>Second</th>\n",
       "      <th>Third</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>106.125798</td>\n",
       "      <td>21.970121</td>\n",
       "      <td>16.118810</td>\n",
       "      <td>91</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>67.226127</td>\n",
       "      <td>19.741782</td>\n",
       "      <td>12.661633</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fare                       survived             \n",
       "class        First     Second      Third    First Second Third\n",
       "sex                                                           \n",
       "female  106.125798  21.970121  16.118810       91     70    72\n",
       "male     67.226127  19.741782  12.661633       45     17    47"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show row data by sex, and column data by class, aggregate survived by using sum, and fare by mean\n",
    "\n",
    "titanic.pivot_table(index='sex', columns='class',aggfunc={'survived':sum, 'fare':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File us-states-cases.csv does not exist: 'us-states-cases.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-81d7d3c79e94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# use Seaborn styles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mstates_cases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'us-states-cases.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File us-states-cases.csv does not exist: 'us-states-cases.csv'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, seaborn as sns, pandas as pd\n",
    "\n",
    "sns.set()  # use Seaborn styles\n",
    "states_cases = pd.read_csv('us-states-cases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    8,   27,   64,  125,  216,  343,  512,  729, 1000],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an np array x based on range(11). Output the cubed contents of x\n",
    "\n",
    "x = np.array(range(11))\n",
    "x ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEW YORK', 'LONDON', 'TOKYO', 'SEOUL']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use list comprehension with a list of string to convert all entries to uppercase. \n",
    "\n",
    "cities = ['new york', 'london', 'tokyo', 'seoul']\n",
    "[s.upper() for s in cities]\n",
    "\n",
    "# What happens when the list contains the value of None? \n",
    "# - an AttributeError is thrown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NEW YORK\n",
       "1      LONDON\n",
       "2       TOKYO\n",
       "3       SEOUL\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list from the previous requirement into a Pandas series.\n",
    "\n",
    "p_cities = pd.Series(cities)\n",
    "\n",
    "# Demonstrate conversion to uppercase with the Pandas series\n",
    "p_cities.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uppercase:\n",
      " 0            TEXAS\n",
      "1          FLORIDA\n",
      "2          GEORGIA\n",
      "3     SOUTH DAKOTA\n",
      "4    NEW HAMPSHIRE\n",
      "dtype: object\n",
      "\n",
      "lowercase:\n",
      " 0            texas\n",
      "1          florida\n",
      "2          georgia\n",
      "3     south dakota\n",
      "4    new hampshire\n",
      "dtype: object\n",
      "\n",
      "length:\n",
      " 0     5\n",
      "1     7\n",
      "2     7\n",
      "3    12\n",
      "4    13\n",
      "dtype: int64\n",
      "\n",
      "ends with A:\n",
      " 0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "split:\n",
      " 0             [Texas]\n",
      "1           [Florida]\n",
      "2           [Georgia]\n",
      "3     [South, Dakota]\n",
      "4    [New, Hampshire]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the use of five Pandas str methods on a Pandas series named states \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "states = pd.Series(['Texas','Florida','Georgia','South Dakota','New Hampshire'])\n",
    "print (\"uppercase:\\n\", states.str.upper())\n",
    "print (\"\\nlowercase:\\n\", states.str.lower())\n",
    "print (\"\\nlength:\\n\", states.str.len())\n",
    "print (\"\\nends with A:\\n\", states.str.endswith('a'))\n",
    "print (\"\\nsplit:\\n\", states.str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Texas\n",
      "1          Florida\n",
      "2          Georgia\n",
      "3     South Dakota\n",
      "4    New Hampshire\n",
      "dtype: object\n",
      "\n",
      "two words:\n",
      " 0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "dtype: bool\n",
      "\n",
      "ends with consonant + A:\n",
      " 0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "number of vowels:\n",
      " 0    2\n",
      "1    3\n",
      "2    4\n",
      "3    5\n",
      "4    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the use of three regular expression examples using the states Pandas series.\n",
    "\n",
    "print (states)\n",
    "print (\"\\ntwo words:\\n\", states.str.match('([A-Za-z]+)\\s'))\n",
    "print (\"\\nends with consonant + A:\\n\", states.str.contains('[a-z][a]$'))\n",
    "print (\"\\nnumber of vowels:\\n\", states.str.count('[a]|[e]|[o]|[u]|[i]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:\n",
      " 0    T\n",
      "1    F\n",
      "2    G\n",
      "3    S\n",
      "4    N\n",
      "dtype: object\n",
      "join:\n",
      " 0                    T+e+x+a+s\n",
      "1                F+l+o+r+i+d+a\n",
      "2                G+e+o+r+g+i+a\n",
      "3      S+o+u+t+h+ +D+a+k+o+t+a\n",
      "4    N+e+w+ +H+a+m+p+s+h+i+r+e\n",
      "dtype: object\n",
      "concatenate:\n",
      " TexasFloridaGeorgiaSouth DakotaNew Hampshire\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the use of three miscellaneous methods using the states Pandas series. \n",
    "\n",
    "print (\"index:\\n\", states.str.get(0))\n",
    "print (\"join:\\n\", states.str.join('+'))\n",
    "print (\"concatenate:\\n\", states.str.cat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use markdown to describe the operations demonstrated in the section Example: Recipe Database in chapter 03.10.\n",
    "1. Construct a string representation containing all JSON entries then load it in with pd.read_json\n",
    "2. Get an idea of what the data looks like by doing: recipes.shape, recipes.iloc[0], and .describe() \n",
    "3. Gather information on certain types of recipes using regular expressions and vectorized string operations such as .contains()\n",
    "4. Pick out recipes that satisfy certain requirements by generating a Boolean dataframe and querying from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seven dates: ['2020-01-01' '2020-01-02' '2020-01-03' '2020-01-04' '2020-01-05'\n",
      " '2020-01-06' '2020-01-07']\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy date array using the date 01Jan2020.  Use the arange() method to create an array of seven dates\n",
    "\n",
    "date = np.array('2020-01-01', dtype=np.datetime64)\n",
    "print (\"seven dates:\", date +  np.arange(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003-06-18        Asha\n",
       "2010-01-24       Ishan\n",
       "1968-07-13     Pradeep\n",
       "1970-06-12    Bhaswati\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a Pandas series object and use it to demonstrate indexing data by timestamps.\n",
    "\n",
    "dates = pd.DatetimeIndex(['2003-06-18', '2010-01-24',\n",
    "                          '1968-07-13', '1970-06-12'])\n",
    "birthdates = pd.Series([\"Asha\", \"Ishan\", \"Pradeep\", \"Bhaswati\"], index=dates)\n",
    "birthdates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>160.729996</td>\n",
       "      <td>158.330002</td>\n",
       "      <td>158.779999</td>\n",
       "      <td>160.619995</td>\n",
       "      <td>22622100.0</td>\n",
       "      <td>159.737595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>159.949997</td>\n",
       "      <td>158.059998</td>\n",
       "      <td>158.320007</td>\n",
       "      <td>158.619995</td>\n",
       "      <td>21116200.0</td>\n",
       "      <td>157.748581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>159.100006</td>\n",
       "      <td>156.509995</td>\n",
       "      <td>157.080002</td>\n",
       "      <td>159.029999</td>\n",
       "      <td>20813700.0</td>\n",
       "      <td>158.156342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>159.669998</td>\n",
       "      <td>157.320007</td>\n",
       "      <td>159.320007</td>\n",
       "      <td>157.580002</td>\n",
       "      <td>21634100.0</td>\n",
       "      <td>156.714310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>160.800003</td>\n",
       "      <td>157.949997</td>\n",
       "      <td>158.929993</td>\n",
       "      <td>160.089996</td>\n",
       "      <td>27746500.0</td>\n",
       "      <td>159.210495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-25</th>\n",
       "      <td>154.330002</td>\n",
       "      <td>144.440002</td>\n",
       "      <td>148.910004</td>\n",
       "      <td>146.919998</td>\n",
       "      <td>75638200.0</td>\n",
       "      <td>146.511948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-26</th>\n",
       "      <td>156.660004</td>\n",
       "      <td>148.369995</td>\n",
       "      <td>148.399994</td>\n",
       "      <td>156.110001</td>\n",
       "      <td>64568100.0</td>\n",
       "      <td>155.676437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-27</th>\n",
       "      <td>154.889999</td>\n",
       "      <td>149.199997</td>\n",
       "      <td>151.750000</td>\n",
       "      <td>149.699997</td>\n",
       "      <td>57042300.0</td>\n",
       "      <td>149.284225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>160.600006</td>\n",
       "      <td>150.009995</td>\n",
       "      <td>152.440002</td>\n",
       "      <td>160.229996</td>\n",
       "      <td>63420300.0</td>\n",
       "      <td>159.784988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>164.779999</td>\n",
       "      <td>156.559998</td>\n",
       "      <td>159.399994</td>\n",
       "      <td>157.710007</td>\n",
       "      <td>77927200.0</td>\n",
       "      <td>157.271988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close      Volume  \\\n",
       "Date                                                                     \n",
       "2020-01-02  160.729996  158.330002  158.779999  160.619995  22622100.0   \n",
       "2020-01-03  159.949997  158.059998  158.320007  158.619995  21116200.0   \n",
       "2020-01-06  159.100006  156.509995  157.080002  159.029999  20813700.0   \n",
       "2020-01-07  159.669998  157.320007  159.320007  157.580002  21634100.0   \n",
       "2020-01-08  160.800003  157.949997  158.929993  160.089996  27746500.0   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-03-25  154.330002  144.440002  148.910004  146.919998  75638200.0   \n",
       "2020-03-26  156.660004  148.369995  148.399994  156.110001  64568100.0   \n",
       "2020-03-27  154.889999  149.199997  151.750000  149.699997  57042300.0   \n",
       "2020-03-30  160.600006  150.009995  152.440002  160.229996  63420300.0   \n",
       "2020-03-31  164.779999  156.559998  159.399994  157.710007  77927200.0   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2020-01-02  159.737595  \n",
       "2020-01-03  157.748581  \n",
       "2020-01-06  158.156342  \n",
       "2020-01-07  156.714310  \n",
       "2020-01-08  159.210495  \n",
       "...                ...  \n",
       "2020-03-25  146.511948  \n",
       "2020-03-26  155.676437  \n",
       "2020-03-27  149.284225  \n",
       "2020-03-30  159.784988  \n",
       "2020-03-31  157.271988  \n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a Pandas DataReader object to show the stock prices of a ticker symbol of your choice (e.g. MSFT, GS, TEAM) \n",
    "\n",
    "from pandas_datareader import data\n",
    "\n",
    "msft = data.DataReader('MSFT', start='2020-01-01', end='2020-03-31', data_source='yahoo')\n",
    "msft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.35 ms Â± 81.3 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n",
      "4.77 ms Â± 158 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Use the timeit function to compare processes summing four Pandas dataframe objects using:\n",
    "\n",
    "df1, df2, df3, df4 = (pd.DataFrame(rng.randint(0, 1000, (100, 3))) for i in range(4))\n",
    "\n",
    "# the typical approach (simple â€˜+â€™ operations)\n",
    "%timeit df1 + df2 + df3 + df4\n",
    "\n",
    "# the pd.eval() approach\n",
    "%timeit pd.eval('df1 + df2 + df3 + df4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Watched videos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through completing Assignment 12 I learned various ways to search, manipulate, and reorganize pandas DataFrames and other data structures. I was previously confused on what exactly the purpose of RandomState was, so I was glad there was an exercise focused on RandomState in this assignment so that I could understand it a bit better. I am currently working on a data visualization project with a group of friends, and we are using COVID-19 and socioeconomic data from AWS Datasets. I hope to apply the techniques I learn in this course to help me work with that data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
